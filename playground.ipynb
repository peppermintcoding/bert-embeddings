{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be 11 Tokens for Bert\n",
    "sentence = \"Sphinx of black quartz, judge my vow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the special tokens.\n",
    "marked_text = f\"[CLS] {sentence} [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "segments_ids = [1 for _ in range(len(tokenized_text))]\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[-1]\n",
    "\n",
    "\n",
    "# `hidden_states` has shape [13 x 1 x 11 x 768]\n",
    "# `token_vecs` is a tensor with shape [11 x 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "corpus = \"\"\"So she was considering in her own mind (as well as she could,\n",
    "            for the hot day made her feel very sleepy and stupid), whether\n",
    "            the pleasure of making a daisy-chain would be worth the trouble\n",
    "            of getting up and picking the daisies, when suddenly a White\n",
    "            Rabbit with pink eyes ran close by her.\"\"\".split()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(3, len(corpus)):\n",
    "\n",
    "    corpus_embeddings = embedder.encode(corpus[:i], convert_to_tensor=True)\n",
    "    three_dim = PCA(n_components=3, random_state=0).fit_transform(corpus_embeddings)\n",
    "\n",
    "    df = pd.DataFrame(data=[x for x in three_dim], columns=[\"x\", \"y\", \"z\"])\n",
    "    df[\"label\"] = corpus[:i]\n",
    "    df[\"frame\"] = i\n",
    "    df = pd.concat([df, df])\n",
    "\n",
    "# normalize\n",
    "df[\"x\"] = (df[\"x\"] - df[\"x\"].min()) / (df[\"x\"].max() - df[\"x\"].min())\n",
    "df[\"y\"] = (df[\"y\"] - df[\"y\"].min()) / (df[\"y\"].max() - df[\"y\"].min())\n",
    "df[\"z\"] = (df[\"z\"] - df[\"z\"].min()) / (df[\"z\"].max() - df[\"z\"].min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.decomposition import KernelPCA\n",
    "import pandas as pd\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def create_pca_colors(corpus: list, normalize: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Converts a list of words or sentences to color vectors\n",
    "    via PCA dimensionality reduction. Uses the all-MiniLM-l6-v2\n",
    "    Model for embeddings.\n",
    "    \n",
    "    Params:\n",
    "        corpus: a list of strings, either words or sentences\n",
    "        normalize: optional, already normalized the values to 0-1\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: red, green, blue, label\n",
    "    \n",
    "    NOTE: PCA and KernelPCA (with non linear Kernel) give\n",
    "    equal results.\n",
    "    NOTE: TSNE was excluded here because of the higher\n",
    "    computational cost in high dimensions > 50\n",
    "    \"\"\"\n",
    "    corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "    three_dim = KernelPCA(n_components=3, random_state=0, kernel=\"poly\").fit_transform(corpus_embeddings)\n",
    "\n",
    "    df = pd.DataFrame(data=[x for x in three_dim], columns=[\"red\", \"green\", \"blue\"])\n",
    "    df[\"label\"] = corpus\n",
    "\n",
    "    if normalize:\n",
    "        df[\"red\"] = (df[\"red\"] - df[\"red\"].min()) / (df[\"red\"].max() - df[\"red\"].min())\n",
    "        df[\"green\"] = (df[\"green\"] - df[\"green\"].min()) / (df[\"green\"].max() - df[\"green\"].min())\n",
    "        df[\"blue\"] = (df[\"blue\"] - df[\"blue\"].min()) / (df[\"blue\"].max() - df[\"blue\"].min())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imageio.v2 as imageio\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "\n",
    "\n",
    "def save_as_gif(colors: pd.DataFrame, filepath: str, size: tuple = (300, 300), freq: int = 5, font_size: int = 25):\n",
    "    \"\"\"Creates and saves a gif from the word to color DataFrame\n",
    "    \n",
    "    Params:\n",
    "        colors: DataFrame with red, green, blue, label\n",
    "        filepath: destination for gif\n",
    "        size: a tuple with (width, height)\n",
    "        freq: repeat rate of frames per color, higher value -> longer per color\n",
    "        font_size: size of the text\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    fnt = ImageFont.truetype(\"FreeMono.ttf\", font_size)\n",
    "    for _, row in colors.iterrows():\n",
    "        img = Image.new(\"RGB\", size, (int(row[\"red\"]*255), int(row[\"green\"]*255), int(row[\"blue\"]*255)))\n",
    "        ctx = ImageDraw.Draw(img)\n",
    "        ctx.text((100, 100), row[\"label\"], fill=(255, 255, 255), font=fnt, stroke_width=1)\n",
    "        for _ in range(freq):\n",
    "            images.append(img)\n",
    "    imageio.mimsave(filepath, images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"So she was considering in her own mind (as well as she could,\n",
    "            for the hot day made her feel very sleepy and stupid), whether\n",
    "            the pleasure of making a daisy-chain would be worth the trouble\n",
    "            of getting up and picking the daisies, when suddenly a White\n",
    "            Rabbit with pink eyes ran close by her.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.231364703270346e+31"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for linearity of the color space\n",
    "# using PCA or kernel PCA with a POLY KERNEL does not change\n",
    "# the output too much\n",
    "colors = create_pca_colors(corpus)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = colors[\"red\"].to_numpy().reshape(-1, 1)\n",
    "Y = colors[\"blue\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "regressor = LinearRegression().fit(X, Y)\n",
    "r2_score(regressor.predict(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = create_pca_colors(corpus)\n",
    "save_as_gif(colors, \"test2.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out feeding in a sliding window over the text\n",
    "# what length is the best? Make it to short and the change isn't smooth anymore\n",
    "# make it to large and there is no change?\n",
    "# coming up next!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
