{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be 11 Tokens for Bert\n",
    "sentence = \"Sphinx of black quartz, judge my vow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the special tokens.\n",
    "marked_text = f\"[CLS] {sentence} [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "segments_ids = [1 for _ in range(len(tokenized_text))]\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[-1]\n",
    "\n",
    "\n",
    "# `hidden_states` has shape [13 x 1 x 11 x 768]\n",
    "# `token_vecs` is a tensor with shape [11 x 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "corpus = \"\"\"So she was considering in her own mind (as well as she could,\n",
    "            for the hot day made her feel very sleepy and stupid), whether\n",
    "            the pleasure of making a daisy-chain would be worth the trouble\n",
    "            of getting up and picking the daisies, when suddenly a White\n",
    "            Rabbit with pink eyes ran close by her.\"\"\".split()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(3, len(corpus)):\n",
    "\n",
    "    corpus_embeddings = embedder.encode(corpus[:i], convert_to_tensor=True)\n",
    "    three_dim = PCA(n_components=3, random_state=0).fit_transform(corpus_embeddings)\n",
    "\n",
    "    df = pd.DataFrame(data=[x for x in three_dim], columns=[\"x\", \"y\", \"z\"])\n",
    "    df[\"label\"] = corpus[:i]\n",
    "    df[\"frame\"] = i\n",
    "    df = pd.concat([df, df])\n",
    "\n",
    "# normalize\n",
    "df[\"x\"] = (df[\"x\"] - df[\"x\"].min()) / (df[\"x\"].max() - df[\"x\"].min())\n",
    "df[\"y\"] = (df[\"y\"] - df[\"y\"].min()) / (df[\"y\"].max() - df[\"y\"].min())\n",
    "df[\"z\"] = (df[\"z\"] - df[\"z\"].min()) / (df[\"z\"].max() - df[\"z\"].min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.decomposition import KernelPCA\n",
    "import pandas as pd\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def create_pca_colors(corpus: list, normalize: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Converts a list of words or sentences to color vectors\n",
    "    via PCA dimensionality reduction. Uses the all-MiniLM-l6-v2\n",
    "    Model for embeddings.\n",
    "    \n",
    "    Params:\n",
    "        corpus: a list of strings, either words or sentences\n",
    "        normalize: optional, will normalize the values to 0-1\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: red, green, blue, label\n",
    "    \n",
    "    NOTE: PCA and KernelPCA (with non linear Kernel) give\n",
    "    equal results.\n",
    "    NOTE: TSNE was excluded here because of the higher\n",
    "    computational cost in high dimensions > 50\n",
    "    \"\"\"\n",
    "    corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "    three_dim = KernelPCA(n_components=3, random_state=0, kernel=\"poly\").fit_transform(corpus_embeddings)\n",
    "\n",
    "    df = pd.DataFrame(data=[x for x in three_dim], columns=[\"red\", \"green\", \"blue\"])\n",
    "    df[\"label\"] = corpus\n",
    "\n",
    "    if normalize:\n",
    "        df[\"red\"] = (df[\"red\"] - df[\"red\"].min()) / (df[\"red\"].max() - df[\"red\"].min())\n",
    "        df[\"green\"] = (df[\"green\"] - df[\"green\"].min()) / (df[\"green\"].max() - df[\"green\"].min())\n",
    "        df[\"blue\"] = (df[\"blue\"] - df[\"blue\"].min()) / (df[\"blue\"].max() - df[\"blue\"].min())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_interpolated_colors(num_colors: int, c1: np.ndarray, c2: np.ndarray) -> list:\n",
    "    \"\"\"Interpolates linearly between two colors\n",
    "    and returns a list of the color gradient c1 -- num_colors -- c2\n",
    "    \"\"\"\n",
    "    segment_len = np.linalg.norm(c2 - c1) / (num_colors+1)\n",
    "    t = (c2 - c1) / np.linalg.norm(c2 - c1)\n",
    "    return [c1 + t*segment_len*i for i in range(num_colors+2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "\n",
    "def save_as_gif(colors: pd.DataFrame, filepath: str, size: tuple = (300, 300), freq: int = 5,\n",
    "                font_size: int = 25, interpolate: bool = False):\n",
    "    \"\"\"Creates and saves a gif from the word to color DataFrame\n",
    "    \n",
    "    Params:\n",
    "        colors: DataFrame with red, green, blue, label\n",
    "        filepath: destination for gif\n",
    "        size: a tuple with (width, height)\n",
    "        freq: repeat rate of frames per color, higher value -> longer per color\n",
    "        font_size: size of the text\n",
    "        interpolate: optional, linearly interpolates between different colors for smoother transition\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    fnt = PIL.ImageFont.truetype(\"FreeMono.ttf\", font_size)\n",
    "    for i, row in colors.iterrows():\n",
    "        if interpolate:\n",
    "            c1 = np.array([row[\"red\"], row[\"green\"], row[\"blue\"]])\n",
    "            if i < colors.shape[0]-1:\n",
    "                row_2 = colors.iloc[i+1, :]\n",
    "                c2 = np.array([row_2[\"red\"], row_2[\"green\"], row_2[\"blue\"]])\n",
    "            else:\n",
    "                c2 = c1.copy()\n",
    "            # leave out the last element because it is the next color in the cycle\n",
    "            gradient = get_interpolated_colors(freq-1, c1, c2)[:-1]\n",
    "            for c in gradient:\n",
    "                img = PIL.Image.new(\"RGB\", size, tuple((c*255).astype(int)))\n",
    "                ctx = PIL.ImageDraw.Draw(img)\n",
    "                label = \" \".join(row[\"label\"])\n",
    "                ctx.text((50, 100), label, fill=(255, 255, 255), font=fnt, stroke_width=1)\n",
    "                images.append(img)\n",
    "        else:\n",
    "            img = PIL.Image.new(\"RGB\", size, (int(row[\"red\"]*255), int(row[\"green\"]*255), int(row[\"blue\"]*255)))\n",
    "            ctx = PIL.ImageDraw.Draw(img)\n",
    "            label = \" \".join(row[\"label\"])\n",
    "            ctx.text((100, 100), label, fill=(255, 255, 255), font=fnt, stroke_width=1)\n",
    "            for _ in range(freq):\n",
    "                images.append(img)\n",
    "    imageio.mimsave(filepath, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sliding_window_corpus(corpus: str, wl: int) -> list:\n",
    "    \"\"\"Creates a list of sentence fragments\n",
    "    \n",
    "    Params:\n",
    "        corpus: the text as one string\n",
    "        wl: the window length of the sliding window (in words)\n",
    "    \n",
    "    Return:\n",
    "        A list of strings with word length wl\n",
    "    \"\"\"\n",
    "    words = corpus.split()\n",
    "    return [words[i:i+wl] for i in range(len(words)-wl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_punctuation(s: str) -> str:\n",
    "    \"\"\"Removes punctuation from the string\"\"\"\n",
    "    return re.sub(r\"[^\\w\\s]\", \"\", s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"So she was considering in her own mind (as well as she could,\n",
    "            for the hot day made her feel very sleepy and stupid), whether\n",
    "            the pleasure of making a daisy-chain would be worth the trouble\n",
    "            of getting up and picking the daisies, when suddenly a White\n",
    "            Rabbit with pink eyes ran close by her.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sliding_window_corpus(corpus, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = create_pca_colors(corpus.split())\n",
    "save_as_gif(colors, \"test.gif\", interpolate=True, size=(500, 500))\n",
    "from IPython.display import Image\n",
    "Image(\"test.gif\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for linearity of the color space\n",
    "# using PCA or kernel PCA with a POLY KERNEL does not change\n",
    "# the output too much\n",
    "colors = create_pca_colors(corpus)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = colors[\"red\"].to_numpy().reshape(-1, 1)\n",
    "Y = colors[\"blue\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "regressor = LinearRegression().fit(X, Y)\n",
    "r2_score(regressor.predict(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: upper case and lower case makes a difference, as well as punctuation\n",
    "# should we exclude punctuation?\n",
    "colors = create_pca_colors(\"Some Some, some some. some!\".split())\n",
    "save_as_gif(colors, \"test.gif\")\n",
    "from IPython.display import Image\n",
    "Image(\"test.gif\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize with Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [\n",
    "    \"But what about second breakfast?\",\n",
    "    \"Don't think he knows about second breakfast, Pip.\",\n",
    "    \"What about elevensies?\",\n",
    "]\n",
    "encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "    outputs = model(encoded_input[\"input_ids\"], encoded_input[\"attention_mask\"])\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[-1]\n",
    "\n",
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
